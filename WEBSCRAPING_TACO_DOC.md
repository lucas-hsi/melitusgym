# Documenta√ß√£o: Web Scraping TACO

## Resumo das Implementa√ß√µes

### 1. M√≥dulo de Web Scraping (`taco_scraper.py`)

**Localiza√ß√£o:** `backend/app/services/taco_scraper.py`

**Funcionalidades:**
- Web scraping da tabela TACO online
- Cache LRU (`@lru_cache`) para otimizar performance
- Tratamento robusto de erros (timeout, HTTP errors, parsing errors)
- Normaliza√ß√£o de texto para melhor matching
- Parsing de valores num√©ricos com formato PT-BR

**Classes:**
- `TACOWebScraper`: Classe principal do scraper
  - `search_foods(query, limit)`: Busca alimentos na TACO online
  - `clear_cache()`: Limpa cache de requisi√ß√µes
  - `_fetch_page(query)`: Busca p√°gina HTML (com cache)
  - `_parse_food_table(html, query)`: Faz parsing da tabela HTML

**Fun√ß√£o auxiliar:**
- `get_taco_scraper()`: Retorna inst√¢ncia singleton do scraper

### 2. Endpoint REST

**Rota:** `GET /api/taco/search`

**Par√¢metros de Query:**
- `query` (string, obrigat√≥rio): Termo de busca (m√≠nimo 2 caracteres)
- `limit` (int, opcional): N√∫mero m√°ximo de resultados (1-50, padr√£o: 20)

**Exemplo de Requisi√ß√£o:**
```bash
GET /api/taco/search?query=arroz&limit=10
```

**Resposta de Sucesso (200):**
```json
{
  "query": "arroz",
  "items": [
    {
      "nome": "Arroz branco cozido",
      "categoria": "Cereais",
      "kcal": 130.0,
      "carb": 28.1,
      "prot": 2.5,
      "lip": 0.2,
      "fibra": 0.4,
      "porcao": "100g",
      "porcao_gr": 100.0
    }
  ],
  "count": 1,
  "total_found": 1,
  "source": "taco_online",
  "cached": false,
  "search_time_ms": 245.67,
  "timestamp": "2024-11-03T19:12:00"
}
```

**Respostas de Erro:**

**400 - Bad Request:**
```json
{
  "error": "invalid_query",
  "message": "O termo de busca deve ter pelo menos 2 caracteres",
  "timestamp": "2024-11-03T19:12:00"
}
```

**503 - Service Unavailable:**
```json
{
  "query": "arroz",
  "items": [],
  "count": 0,
  "error": "N√£o foi poss√≠vel acessar o site da TACO",
  "message": "Servi√ßo de scraping TACO temporariamente indispon√≠vel",
  "timestamp": "2024-11-03T19:12:00"
}
```

**500 - Internal Server Error:**
```json
{
  "query": "arroz",
  "items": [],
  "count": 0,
  "error": "internal_error",
  "message": "Erro ao buscar alimentos TACO: ...",
  "timestamp": "2024-11-03T19:12:00"
}
```

### 3. Campos Retornados

Cada item no array `items` cont√©m:
- **nome** (string): Nome do alimento
- **categoria** (string): Categoria/grupo alimentar
- **kcal** (float|null): Energia em kcal por 100g
- **carb** (float|null): Carboidratos em g por 100g
- **prot** (float|null): Prote√≠nas em g por 100g
- **lip** (float|null): Lip√≠dios em g por 100g
- **fibra** (float|null): Fibras em g por 100g
- **porcao** (string): Descri√ß√£o da por√ß√£o (ex: "100g")
- **porcao_gr** (float): Por√ß√£o em gramas

### 4. Depend√™ncias Adicionadas

No `requirements.txt`:
```
beautifulsoup4==4.12.2
lxml==4.9.3
```

### 5. Cache e Performance

**Estrat√©gia de Cache:**
- Cache LRU em mem√≥ria com `functools.lru_cache`
- Tamanho m√°ximo: 100 queries
- Cache aplicado na fun√ß√£o `_fetch_page` para evitar requisi√ß√µes duplicadas

**Performance:**
- Timeout de requisi√ß√µes HTTP: 10 segundos
- Parsing otimizado com BeautifulSoup e lxml
- Logging estruturado para monitoramento

### 6. Tratamento de Erros

**N√≠veis de Tratamento:**
1. **Valida√ß√£o de entrada**: Query m√≠nima de 2 chars, limit entre 1-50
2. **Timeout HTTP**: Retorna erro 503 se site n√£o responder
3. **Parsing HTML**: Trata tabelas ausentes ou malformadas
4. **Valores num√©ricos**: Converte formatos PT-BR (v√≠rgula para ponto)
5. **Fallback**: Retorna array vazio em caso de erro, nunca quebra

### 7. Logging

Todas as opera√ß√µes s√£o logadas com n√≠veis apropriados:
- `INFO`: Opera√ß√µes bem-sucedidas, inicializa√ß√µes
- `WARNING`: Estruturas HTML inesperadas, dados ausentes
- `ERROR`: Falhas HTTP, timeouts, exce√ß√µes

**Exemplos de Logs:**
```
üï∑Ô∏è TACO Web Scraper inicializado (cache_size=100, timeout=10s)
üåê Buscando p√°gina TACO para query: 'arroz'
‚úÖ P√°gina obtida com sucesso (status=200)
üìä Total de alimentos parseados: 15
‚úÖ Busca TACO online conclu√≠da: 'arroz' - 15 resultados em 245.67ms
```

### 8. Integra√ß√£o com Frontend

**Uso no React/Next.js:**
```typescript
const searchTaco = async (query: string, limit: number = 20) => {
  const response = await fetch(
    `/api/taco/search?query=${encodeURIComponent(query)}&limit=${limit}`
  );
  
  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message);
  }
  
  return await response.json();
};

// Uso
const results = await searchTaco("arroz", 10);
console.log(`Encontrados ${results.count} alimentos`);
```

### 9. Notas Importantes

‚ö†Ô∏è **IMPORTANTE:** A URL do site TACO (`BASE_URL` e `SEARCH_URL`) no arquivo `taco_scraper.py` s√£o exemplos gen√©ricos. **Voc√™ deve ajustar** essas URLs e os seletores CSS no m√©todo `_parse_food_table` para corresponder √† estrutura real do site que ser√° usado para scraping.

**Ajustes necess√°rios:**
1. Verificar URL correta da base TACO online
2. Inspecionar estrutura HTML da tabela de resultados
3. Ajustar seletores CSS/XPath no m√©todo `_parse_food_table`
4. Validar √≠ndices das colunas da tabela

### 10. Testes Sugeridos

```bash
# Teste b√°sico
curl "http://localhost:8000/api/taco/search?query=arroz&limit=5"

# Teste com query curta (deve retornar erro 400)
curl "http://localhost:8000/api/taco/search?query=a"

# Teste com limit inv√°lido (deve retornar erro 400)
curl "http://localhost:8000/api/taco/search?query=arroz&limit=100"

# Teste com caracteres especiais
curl "http://localhost:8000/api/taco/search?query=feij%C3%A3o&limit=10"
```

### 11. Melhorias Futuras

- [ ] Adicionar cache persistente (Redis/Memcached)
- [ ] Implementar rate limiting para proteger o site TACO
- [ ] Adicionar suporte a pagina√ß√£o
- [ ] Melhorar detec√ß√£o de cache no response
- [ ] Adicionar m√©tricas de performance (Prometheus)
- [ ] Implementar fallback para base local em caso de falha
- [ ] Adicionar testes unit√°rios e de integra√ß√£o

---

## Checklist de Deploy

- [x] C√≥digo implementado
- [x] Depend√™ncias adicionadas ao `requirements.txt`
- [x] Endpoint documentado
- [x] Logging implementado
- [x] Tratamento de erros robusto
- [ ] URLs e seletores ajustados para site real
- [ ] Testes manuais realizados
- [ ] Testes automatizados criados
- [ ] Documenta√ß√£o de API atualizada
- [ ] Frontend integrado
- [ ] Deploy em ambiente de staging
- [ ] Monitoramento configurado
